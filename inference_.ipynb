{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YSTVcmkRyDPl",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'vision' already exists and is not an empty directory.\n",
      "HEAD is now at 2f40a483d7 [v0.8.X] .circleci: Add Python 3.9 to CI (#3063)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "git checkout v0.8.2\n",
    "\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW8fUoAgvZbK",
    "outputId": "b216a202-3d2b-4543-c687-08f464fde544",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# From the torchvision references we cloned\n",
    "import transforms as T\n",
    "import fiftyone as fo\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import skimage.io as io\n",
    "import fiftyone as fo\n",
    "import pycocotools \n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from pycocotools import mask as maskUtils\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rydiTBeqIxKp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHECKPOINT=True\n",
    "NUM_CLASSES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Shell execute - run shell command and capture output (!! is short-hand).\n",
       "\n",
       "%sx command\n",
       "\n",
       "IPython will run the given command using commands.getoutput(), and\n",
       "return the result formatted as a list (split on '\\n').  Since the\n",
       "output is _returned_, it will be stored in ipython's regular output\n",
       "cache Out[N] and in the '_N' automatic variables.\n",
       "\n",
       "Notes:\n",
       "\n",
       "1) If an input line begins with '!!', then %sx is automatically\n",
       "invoked.  That is, while::\n",
       "\n",
       "  !ls\n",
       "\n",
       "causes ipython to simply issue system('ls'), typing::\n",
       "\n",
       "  !!ls\n",
       "\n",
       "is a shorthand equivalent to::\n",
       "\n",
       "  %sx ls\n",
       "\n",
       "2) %sx differs from %sc in that %sx automatically splits into a list,\n",
       "like '%sc -l'.  The reason for this is to make it as easy as possible\n",
       "to process line-oriented shell output via further python commands.\n",
       "%sc is meant to provide much finer control, but requires more\n",
       "typing.\n",
       "\n",
       "3) Just like %sc -l, this is a list with special attributes:\n",
       "::\n",
       "\n",
       "  .l (or .list) : value as list.\n",
       "  .n (or .nlstr): value as newline-separated string.\n",
       "  .s (or .spstr): value as whitespace-separated string.\n",
       "\n",
       "This is very useful when trying to use such lists as arguments to\n",
       "system commands.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.8/site-packages/IPython/core/magics/osm.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GwEqV1Fgbnd"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "# Import required libraries\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = r'../validation-dataset/'\n",
    "def scan_FF(scan_path):\n",
    "    count = 0\n",
    "    \n",
    "    for path in os.scandir(scan_path):\n",
    "        if path.is_file():\n",
    "            # file_path = scan_path+\"/\"+path\n",
    "            print(\"File:\",os.path.abspath(path))\n",
    "            count += 1\n",
    "        elif os.path.isdir(path):\n",
    "            scan_FF(path)\n",
    "    # print('directory:',scan_path,'file count:', count) \n",
    "\n",
    "scan_FF(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "PATH = r'../validation-dataset/'\n",
    "EXT = \"*.jpg\"\n",
    "all_jpg_files = [file\n",
    "                 for path, subdir, files in os.walk(PATH)\n",
    "                 for file in glob(os.path.join(path, EXT))]\n",
    "# print(all_jpg_files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = pd.DataFrame(columns = ['color','3cr','vehicle','filename','budget_id','file_path'])\n",
    "images['file_path'] = all_jpg_files\n",
    "images['budget_id'] = images.file_path.apply(lambda x: x.split(\"/\")[3])\n",
    "images['filename'] = images.file_path.apply(lambda x: x.split(\"/\")[4])\n",
    "images['color'] = images.file_path.apply(lambda x: x.split(\"/\")[2])\n",
    "images = images.drop(['vehicle'], axis='columns')\n",
    "images.drop('file_path', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../csvs/images.csv'\n",
    "filepath = Path(csv_path)\n",
    "images.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne7AWgQ5ykVg",
    "outputId": "d0c2696a-2226-4987-b8ba-8c7b78f57d8c"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "# Import required libraries\n",
    "import torch\n",
    "import cv2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "img_dir=root_path+\"/dataset/inference/\"\n",
    "img_converted = cv2.imread(img_dir)\n",
    "  \n",
    "# Convert BGR image to RGB image\n",
    "image = cv2.cvtColor(img_converted, cv2.COLOR_BGR2RGB)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "  \n",
    "# transform = transforms.PILToTensor()\n",
    "# Convert the PIL image to Torch tensor\n",
    "img = transform(image)\n",
    "print(type(img))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  prediction=model([img.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdwL4n94ygw-",
    "outputId": "3c1a45e7-55d6-4e9c-a7b4-3172d394d6f4"
   },
   "outputs": [],
   "source": [
    "prediction[0]['labels']\n",
    "#type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBGjm9fS1yyE"
   },
   "outputs": [],
   "source": [
    "QUANT_DETECTION=len(prediction[0]['masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GigMf7D775vt",
    "outputId": "2cf6972f-8baf-4c9b-dfd1-b0dc9b38497f"
   },
   "outputs": [],
   "source": [
    "QUANT_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqYU8_gk4f--"
   },
   "outputs": [],
   "source": [
    "imagem=Image.fromarray(img.mul(255).permute(1,2,0).byte().numpy())\n",
    "mask_predicted=Image.fromarray(prediction[0]['masks'][2,0].mul(255).byte().cpu().numpy())\n",
    "blank = imagem.point(lambda _: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_N2O13408Wuo",
    "outputId": "82b110b0-3747-4b59-f367-062a128f60fe"
   },
   "outputs": [],
   "source": [
    "pred = prediction[0]\n",
    "len(pred['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBHr1rOK8AZI",
    "outputId": "762b347b-6eeb-4c71-b1f1-09997982de91"
   },
   "outputs": [],
   "source": [
    "pred['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpKvkI0K9BNT",
    "outputId": "23a945e4-0dee-4df4-fab3-5df7ce188320"
   },
   "outputs": [],
   "source": [
    "trMASK=0.40\n",
    "confidence=0.8\n",
    "x=0\n",
    "img = imagem\n",
    "width, height = img.size\n",
    "pred = prediction[0]\n",
    "colors=['red','blue','green','yellow','gray','orange','pink','brown','purple','white','black','beige','darkgray','darkred','darkblue','darkgreen','darkyellow']\n",
    "print(len(colors))\n",
    "if len(pred['labels']) > 0:\n",
    "    # print (len(pred['labels']))\n",
    "    mask_labels=[]\n",
    "    count_cor=0\n",
    "    for n in range(len(pred['labels'])):\n",
    "      print(pred['scores'][n])\n",
    "      if pred['scores'][n]>=confidence:\n",
    "        if not pred['labels'][n] in mask_labels:\n",
    "          mask_labels.append(pred['labels'][n])\n",
    "          mask = pred['masks'].cpu().numpy()[n][0]>trMASK\n",
    "          mask = (mask*200).astype(np.uint8)\n",
    "          #print(len(mask_labels))\n",
    "          \n",
    "          mask = Image.fromarray(mask).convert('L')\n",
    "          img2 = Image.new(mode='RGB',size=(width, height),color=colors[len(mask_labels)])\n",
    "          count_cor+=1\n",
    "\n",
    "          img = Image.composite(img2,img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4488G_D-zGph"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][0,0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "resources": {
      "https://localhost:5151/polling?sessionId=f7130546-7e56-4e7e-a338-381ec1d10a61": {
       "data": "eyJtZXNzYWdlcyI6IFtdfQ==",
       "headers": [
        [
         "access-control-allow-headers",
         "x-requested-with"
        ],
        [
         "content-type",
         "text/html; charset=UTF-8"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "WQIqArwTzyuL",
    "outputId": "ca5f8d3b-737b-447b-bc8a-298f87eff2fe"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5DjJOn8BnPG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import fiftyone.utils.coco as fouc\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class FiftyOneTorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\n",
    "    \n",
    "    Args:\n",
    "        fiftyone_dataset: a FiftyOne dataset or view that will be used for training or testing\n",
    "        transforms (None): a list of PyTorch transforms to apply to images and targets when loading\n",
    "        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset that contains the \n",
    "            desired labels to load\n",
    "        classes (None): a list of class strings that are used to define the mapping between\n",
    "            class names and indices. If None, it will use all classes present in the given fiftyone_dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fiftyone_dataset,\n",
    "        transforms=None,\n",
    "        gt_field=\"segmentations\",\n",
    "        classes=None,\n",
    "    ):\n",
    "        self.samples = fiftyone_dataset\n",
    "        self.transforms = transforms\n",
    "        self.gt_field = gt_field\n",
    "\n",
    "        self.img_paths = self.samples.values(\"filepath\")\n",
    "\n",
    "        self.classes = classes\n",
    "        if not self.classes:\n",
    "            # Get list of distinct labels that exist in the view\n",
    "            self.classes = self.samples.distinct(\n",
    "                \"%s.detections.label\" % gt_field\n",
    "            )\n",
    "\n",
    "        if self.classes[0] != \"background\":\n",
    "            self.classes = [\"background\"] + self.classes\n",
    "\n",
    "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        sample = self.samples[img_path]\n",
    "        metadata = sample.metadata\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "        masks=[]\n",
    "        detections = sample[self.gt_field].detections\n",
    "        for det in detections:\n",
    "            category_id = self.labels_map_rev[det.label]\n",
    "            coco_obj = fouc.COCOObject.from_label(\n",
    "                det, metadata, category_id=category_id,\n",
    "            )\n",
    "            segm = coco_obj.segmentation #get the polygons\n",
    "            height=metadata.height\n",
    "            width=metadata.width\n",
    "            #print(coco_obj)\n",
    "            rles = maskUtils.frPyObjects(segm, height, width) #get RLE mask\n",
    "            rle = maskUtils.merge(rles)\n",
    "            mascara = maskUtils.decode(rle) #Transform RLEs masks in bitmaps    \n",
    "            mascara = torch.tensor(mascara, dtype=torch.uint8) #make the bitmap a tensor\n",
    "            masks.append(mascara) #Join mask bitmap tensors\n",
    "            x, y, w, h = coco_obj.bbox\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(coco_obj.category_id)\n",
    "            area.append(coco_obj.area)\n",
    "            iscrowd.append(coco_obj.iscrowd)\n",
    "\n",
    "        #print(type(masks))\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor([idx])\n",
    "        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
    "        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    "\n",
    "        #Masl\n",
    "        masks=torch.stack(masks)\n",
    "        #newMask = torch.cat(newMask, newMask.shape[0]) \n",
    "        target[\"masks\"] = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        #target[\"masks\"]=masks\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vohkrw3YyOgC",
    "outputId": "93d2dd76-1306-47bf-e16d-f7a08ed38860"
   },
   "outputs": [],
   "source": [
    "IMAGES_DIR= root_path+\"/dataset/inference_images\"\n",
    "JSON_DIR = root_path+\"/dataset/labels.json\"\n",
    "\n",
    "NAME=\"C\"\n",
    "data = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    name = NAME,\n",
    "    data_path=IMAGES_DIR,\n",
    "    labels_path=JSON_DIR,\n",
    "    include_id=True,\n",
    "    label_field=\"\",\n",
    "    label_types=\"segmentations\",\n",
    "    extra_attrs=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pH31Y6dszoe-",
    "outputId": "0a36a3a1-ba61-4dc4-f202-23cb9f0e936f"
   },
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([T.ToTensor(), T.RandomHorizontalFlip(0.5)])\n",
    "test_transforms = T.Compose([T.ToTensor()])\n",
    "car_dataset= FiftyOneTorchDataset(data)\n",
    "print(car_dataset)\n",
    "classes=car_dataset.get_classes()\n",
    "print(classes)\n",
    "print(len(classes))\n",
    "\n",
    "torch_dataset_test = FiftyOneTorchDataset(data, test_transforms, \n",
    "        classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPSJ3LwFwsMr",
    "outputId": "3c000bbb-2756-414c-e0c9-b1b87cb3e64e"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Using device %s\" % device)\n",
    "img, _= torch_dataset_test[7]\n",
    "print(type(img))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  prediction=model([img.to(device)])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1A6d09vAyks0",
    "znA3dfXPxIJX",
    "U9K7E5cFH3aL",
    "qpTdh1HsVPDA"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "82857d307ce1481f9a7e77c235ea9ad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ea942994f04078a46593a3d61aed0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "884430e581044c0baca2ecb050350b5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ea942994f04078a46593a3d61aed0f",
      "max": 178090079,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82857d307ce1481f9a7e77c235ea9ad1",
      "value": 178090079
     }
    },
    "8cd38be546ad436fb21c93284c043638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_943bd14ea2cb4da089bcce3894a1b2f2",
       "IPY_MODEL_884430e581044c0baca2ecb050350b5f",
       "IPY_MODEL_bea065ba47c540cbb6fa4dc815f204ce"
      ],
      "layout": "IPY_MODEL_a53e6532c05c4208b508dce84152618b"
     }
    },
    "8dce05e746e84b79ad0032d3582d95c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "943bd14ea2cb4da089bcce3894a1b2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e495d34be69743ef918d417e011fbf3a",
      "placeholder": "​",
      "style": "IPY_MODEL_a4aea13b52154ce6a62821fc42719152",
      "value": "100%"
     }
    },
    "a347b0b195624981854c269a5d0e3c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4aea13b52154ce6a62821fc42719152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a53e6532c05c4208b508dce84152618b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bea065ba47c540cbb6fa4dc815f204ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dce05e746e84b79ad0032d3582d95c4",
      "placeholder": "​",
      "style": "IPY_MODEL_a347b0b195624981854c269a5d0e3c6a",
      "value": " 170M/170M [00:01&lt;00:00, 144MB/s]"
     }
    },
    "e495d34be69743ef918d417e011fbf3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
